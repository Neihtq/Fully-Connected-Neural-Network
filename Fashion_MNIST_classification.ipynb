{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion MNIST classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIvhvt0+wSQhqQpvXgskgU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neihtfool/Fully-Connected-Neural-Network/blob/master/Fashion_MNIST_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvC321YQ6wtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2S8Aw76u67IM",
        "colab_type": "code",
        "outputId": "a1fd4793-14c6-4944-d815-5a5ae85645f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve1zTPy46_kA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_x_orig, train_y), (test_x_orig, test_y) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMZFoWDT73SK",
        "colab_type": "code",
        "outputId": "451b4cce-f778-432e-ffb5-dd28d31b23ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "classes = [\"T-shirt/top\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
        "\n",
        "idx = 1\n",
        "plt.imshow(train_x_orig[idx])\n",
        "print(\"Label: \" + classes[train_y[idx]])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: T-shirt/top\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmEXiYTCLhIJhV0kEv8H/Bn3RW2GnN4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clxDXiRT8-0y",
        "colab_type": "code",
        "outputId": "d1dd6f7e-2641-48df-8b6f-0977cc7b7f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_x_orig.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvsJ6bNX9LyI",
        "colab_type": "code",
        "outputId": "a161985c-ce21-4ec2-c945-fac8ff5473e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train_x = train_x_orig / 255.\n",
        "test_x = test_x_orig / 255.\n",
        "\n",
        "print(\"Shape of train_x: \", train_x.shape)\n",
        "print(\"Shape of train_y: \", train_y.shape)\n",
        "print(\"Shape of test_x: \", test_x.shape)\n",
        "print(\"Shape of test_y: \", test_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_x:  (60000, 28, 28)\n",
            "Shape of train_y:  (60000,)\n",
            "Shape of test_x:  (10000, 28, 28)\n",
            "Shape of test_y:  (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA6pV0jg-DDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dims = [128, 64, 10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h5jm9gE9ift",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(layer_dims):\n",
        "  model = keras.models.Sequential([keras.layers.Flatten(input_shape=(28,28))])\n",
        "  for l in layer_dims[:-1]:\n",
        "    model.add(keras.layers.Dense(l, activation=\"tanh\"))\n",
        "    model.add(keras.layers.Dropout(0.2))\n",
        "  \n",
        "  model.add(keras.layers.Dense(len(classes)))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7TgOTrM_H64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(layer_dims)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5be7_T0_PxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-iTbs3o_oj8",
        "colab_type": "code",
        "outputId": "b5cf122f-0aee-4eb4-a604-7926e62c223f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ez83xT__1jK",
        "colab_type": "code",
        "outputId": "494b5017-9688-42e8-9730-277efabadb6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(train_x, train_y, batch_size=32, epochs=500, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/500\n",
            "48000/48000 [==============================] - 6s 121us/sample - loss: 0.5656 - accuracy: 0.7979 - val_loss: 0.4231 - val_accuracy: 0.8472\n",
            "Epoch 2/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.4457 - accuracy: 0.8383 - val_loss: 0.4121 - val_accuracy: 0.8544\n",
            "Epoch 3/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.4097 - accuracy: 0.8522 - val_loss: 0.3745 - val_accuracy: 0.8667\n",
            "Epoch 4/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.3924 - accuracy: 0.8598 - val_loss: 0.3620 - val_accuracy: 0.8666\n",
            "Epoch 5/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.3787 - accuracy: 0.8612 - val_loss: 0.3583 - val_accuracy: 0.8749\n",
            "Epoch 6/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.3685 - accuracy: 0.8666 - val_loss: 0.3623 - val_accuracy: 0.8712\n",
            "Epoch 7/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.3555 - accuracy: 0.8714 - val_loss: 0.3389 - val_accuracy: 0.8786\n",
            "Epoch 8/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.3442 - accuracy: 0.8748 - val_loss: 0.3321 - val_accuracy: 0.8802\n",
            "Epoch 9/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.3381 - accuracy: 0.8781 - val_loss: 0.3424 - val_accuracy: 0.8751\n",
            "Epoch 10/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.3334 - accuracy: 0.8776 - val_loss: 0.3289 - val_accuracy: 0.8834\n",
            "Epoch 11/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.3262 - accuracy: 0.8807 - val_loss: 0.3258 - val_accuracy: 0.8849\n",
            "Epoch 12/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.3227 - accuracy: 0.8825 - val_loss: 0.3266 - val_accuracy: 0.8832\n",
            "Epoch 13/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.3167 - accuracy: 0.8830 - val_loss: 0.3346 - val_accuracy: 0.8800\n",
            "Epoch 14/500\n",
            "48000/48000 [==============================] - 6s 116us/sample - loss: 0.3131 - accuracy: 0.8862 - val_loss: 0.3230 - val_accuracy: 0.8859\n",
            "Epoch 15/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.3086 - accuracy: 0.8875 - val_loss: 0.3423 - val_accuracy: 0.8818\n",
            "Epoch 16/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.3056 - accuracy: 0.8895 - val_loss: 0.3236 - val_accuracy: 0.8842\n",
            "Epoch 17/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2979 - accuracy: 0.8913 - val_loss: 0.3311 - val_accuracy: 0.8806\n",
            "Epoch 18/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.3002 - accuracy: 0.8896 - val_loss: 0.3224 - val_accuracy: 0.8835\n",
            "Epoch 19/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2989 - accuracy: 0.8897 - val_loss: 0.3317 - val_accuracy: 0.8823\n",
            "Epoch 20/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2908 - accuracy: 0.8940 - val_loss: 0.3235 - val_accuracy: 0.8869\n",
            "Epoch 21/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2911 - accuracy: 0.8945 - val_loss: 0.3299 - val_accuracy: 0.8838\n",
            "Epoch 22/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2888 - accuracy: 0.8937 - val_loss: 0.3247 - val_accuracy: 0.8863\n",
            "Epoch 23/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2868 - accuracy: 0.8943 - val_loss: 0.3255 - val_accuracy: 0.8848\n",
            "Epoch 24/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2813 - accuracy: 0.8961 - val_loss: 0.3209 - val_accuracy: 0.8852\n",
            "Epoch 25/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2811 - accuracy: 0.8969 - val_loss: 0.3224 - val_accuracy: 0.8849\n",
            "Epoch 26/500\n",
            "48000/48000 [==============================] - 5s 115us/sample - loss: 0.2784 - accuracy: 0.8967 - val_loss: 0.3144 - val_accuracy: 0.8900\n",
            "Epoch 27/500\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.2748 - accuracy: 0.8989 - val_loss: 0.3156 - val_accuracy: 0.8913\n",
            "Epoch 28/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.2744 - accuracy: 0.8985 - val_loss: 0.3209 - val_accuracy: 0.8885\n",
            "Epoch 29/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2723 - accuracy: 0.9004 - val_loss: 0.3183 - val_accuracy: 0.8881\n",
            "Epoch 30/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2701 - accuracy: 0.9018 - val_loss: 0.3232 - val_accuracy: 0.8852\n",
            "Epoch 31/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2701 - accuracy: 0.9002 - val_loss: 0.3157 - val_accuracy: 0.8891\n",
            "Epoch 32/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2675 - accuracy: 0.9028 - val_loss: 0.3209 - val_accuracy: 0.8904\n",
            "Epoch 33/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2648 - accuracy: 0.9036 - val_loss: 0.3166 - val_accuracy: 0.8899\n",
            "Epoch 34/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2653 - accuracy: 0.9028 - val_loss: 0.3179 - val_accuracy: 0.8886\n",
            "Epoch 35/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2624 - accuracy: 0.9036 - val_loss: 0.3131 - val_accuracy: 0.8917\n",
            "Epoch 36/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2605 - accuracy: 0.9049 - val_loss: 0.3271 - val_accuracy: 0.8877\n",
            "Epoch 37/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2594 - accuracy: 0.9056 - val_loss: 0.3194 - val_accuracy: 0.8891\n",
            "Epoch 38/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2561 - accuracy: 0.9061 - val_loss: 0.3306 - val_accuracy: 0.8878\n",
            "Epoch 39/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2553 - accuracy: 0.9060 - val_loss: 0.3219 - val_accuracy: 0.8889\n",
            "Epoch 40/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2574 - accuracy: 0.9058 - val_loss: 0.3201 - val_accuracy: 0.8898\n",
            "Epoch 41/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2542 - accuracy: 0.9070 - val_loss: 0.3188 - val_accuracy: 0.8928\n",
            "Epoch 42/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2516 - accuracy: 0.9079 - val_loss: 0.3163 - val_accuracy: 0.8892\n",
            "Epoch 43/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2516 - accuracy: 0.9070 - val_loss: 0.3187 - val_accuracy: 0.8890\n",
            "Epoch 44/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2497 - accuracy: 0.9086 - val_loss: 0.3195 - val_accuracy: 0.8914\n",
            "Epoch 45/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2470 - accuracy: 0.9101 - val_loss: 0.3262 - val_accuracy: 0.8852\n",
            "Epoch 46/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2463 - accuracy: 0.9081 - val_loss: 0.3175 - val_accuracy: 0.8902\n",
            "Epoch 47/500\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.2476 - accuracy: 0.9096 - val_loss: 0.3208 - val_accuracy: 0.8869\n",
            "Epoch 48/500\n",
            "48000/48000 [==============================] - 5s 115us/sample - loss: 0.2492 - accuracy: 0.9087 - val_loss: 0.3193 - val_accuracy: 0.8918\n",
            "Epoch 49/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2430 - accuracy: 0.9098 - val_loss: 0.3221 - val_accuracy: 0.8911\n",
            "Epoch 50/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2424 - accuracy: 0.9121 - val_loss: 0.3276 - val_accuracy: 0.8915\n",
            "Epoch 51/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2438 - accuracy: 0.9097 - val_loss: 0.3255 - val_accuracy: 0.8907\n",
            "Epoch 52/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2418 - accuracy: 0.9106 - val_loss: 0.3217 - val_accuracy: 0.8907\n",
            "Epoch 53/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2390 - accuracy: 0.9124 - val_loss: 0.3232 - val_accuracy: 0.8894\n",
            "Epoch 54/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2379 - accuracy: 0.9125 - val_loss: 0.3255 - val_accuracy: 0.8904\n",
            "Epoch 55/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2376 - accuracy: 0.9133 - val_loss: 0.3216 - val_accuracy: 0.8917\n",
            "Epoch 56/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2372 - accuracy: 0.9135 - val_loss: 0.3177 - val_accuracy: 0.8932\n",
            "Epoch 57/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2334 - accuracy: 0.9154 - val_loss: 0.3178 - val_accuracy: 0.8915\n",
            "Epoch 58/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2356 - accuracy: 0.9124 - val_loss: 0.3237 - val_accuracy: 0.8910\n",
            "Epoch 59/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2369 - accuracy: 0.9137 - val_loss: 0.3269 - val_accuracy: 0.8903\n",
            "Epoch 60/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2304 - accuracy: 0.9155 - val_loss: 0.3350 - val_accuracy: 0.8887\n",
            "Epoch 61/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2328 - accuracy: 0.9151 - val_loss: 0.3199 - val_accuracy: 0.8959\n",
            "Epoch 62/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2277 - accuracy: 0.9156 - val_loss: 0.3236 - val_accuracy: 0.8917\n",
            "Epoch 63/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2277 - accuracy: 0.9176 - val_loss: 0.3232 - val_accuracy: 0.8939\n",
            "Epoch 64/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2274 - accuracy: 0.9173 - val_loss: 0.3246 - val_accuracy: 0.8894\n",
            "Epoch 65/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2305 - accuracy: 0.9151 - val_loss: 0.3294 - val_accuracy: 0.8895\n",
            "Epoch 66/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2299 - accuracy: 0.9157 - val_loss: 0.3208 - val_accuracy: 0.8919\n",
            "Epoch 67/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2230 - accuracy: 0.9178 - val_loss: 0.3276 - val_accuracy: 0.8912\n",
            "Epoch 68/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2272 - accuracy: 0.9173 - val_loss: 0.3206 - val_accuracy: 0.8938\n",
            "Epoch 69/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2261 - accuracy: 0.9180 - val_loss: 0.3189 - val_accuracy: 0.8945\n",
            "Epoch 70/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.2219 - accuracy: 0.9197 - val_loss: 0.3340 - val_accuracy: 0.8894\n",
            "Epoch 71/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2259 - accuracy: 0.9178 - val_loss: 0.3249 - val_accuracy: 0.8919\n",
            "Epoch 72/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2216 - accuracy: 0.9190 - val_loss: 0.3250 - val_accuracy: 0.8900\n",
            "Epoch 73/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2188 - accuracy: 0.9207 - val_loss: 0.3251 - val_accuracy: 0.8902\n",
            "Epoch 74/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2216 - accuracy: 0.9187 - val_loss: 0.3318 - val_accuracy: 0.8923\n",
            "Epoch 75/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2182 - accuracy: 0.9196 - val_loss: 0.3290 - val_accuracy: 0.8907\n",
            "Epoch 76/500\n",
            "48000/48000 [==============================] - 5s 105us/sample - loss: 0.2227 - accuracy: 0.9180 - val_loss: 0.3296 - val_accuracy: 0.8909\n",
            "Epoch 77/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2235 - accuracy: 0.9192 - val_loss: 0.3284 - val_accuracy: 0.8913\n",
            "Epoch 78/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2173 - accuracy: 0.9219 - val_loss: 0.3281 - val_accuracy: 0.8932\n",
            "Epoch 79/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.2174 - accuracy: 0.9207 - val_loss: 0.3389 - val_accuracy: 0.8870\n",
            "Epoch 80/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2176 - accuracy: 0.9207 - val_loss: 0.3244 - val_accuracy: 0.8926\n",
            "Epoch 81/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2153 - accuracy: 0.9213 - val_loss: 0.3295 - val_accuracy: 0.8903\n",
            "Epoch 82/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.2168 - accuracy: 0.9213 - val_loss: 0.3346 - val_accuracy: 0.8897\n",
            "Epoch 83/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2133 - accuracy: 0.9219 - val_loss: 0.3350 - val_accuracy: 0.8912\n",
            "Epoch 84/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2131 - accuracy: 0.9224 - val_loss: 0.3290 - val_accuracy: 0.8942\n",
            "Epoch 85/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.2144 - accuracy: 0.9220 - val_loss: 0.3401 - val_accuracy: 0.8882\n",
            "Epoch 86/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.2134 - accuracy: 0.9221 - val_loss: 0.3254 - val_accuracy: 0.8933\n",
            "Epoch 87/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2127 - accuracy: 0.9226 - val_loss: 0.3254 - val_accuracy: 0.8932\n",
            "Epoch 88/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2123 - accuracy: 0.9229 - val_loss: 0.3328 - val_accuracy: 0.8907\n",
            "Epoch 89/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2113 - accuracy: 0.9233 - val_loss: 0.3373 - val_accuracy: 0.8926\n",
            "Epoch 90/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.2070 - accuracy: 0.9234 - val_loss: 0.3284 - val_accuracy: 0.8922\n",
            "Epoch 91/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2101 - accuracy: 0.9226 - val_loss: 0.3381 - val_accuracy: 0.8908\n",
            "Epoch 92/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2077 - accuracy: 0.9253 - val_loss: 0.3296 - val_accuracy: 0.8934\n",
            "Epoch 93/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.2041 - accuracy: 0.9252 - val_loss: 0.3293 - val_accuracy: 0.8947\n",
            "Epoch 94/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2086 - accuracy: 0.9242 - val_loss: 0.3311 - val_accuracy: 0.8910\n",
            "Epoch 95/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.2045 - accuracy: 0.9252 - val_loss: 0.3379 - val_accuracy: 0.8910\n",
            "Epoch 96/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.2005 - accuracy: 0.9269 - val_loss: 0.3355 - val_accuracy: 0.8933\n",
            "Epoch 97/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2052 - accuracy: 0.9258 - val_loss: 0.3394 - val_accuracy: 0.8902\n",
            "Epoch 98/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.2005 - accuracy: 0.9292 - val_loss: 0.3385 - val_accuracy: 0.8935\n",
            "Epoch 99/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2040 - accuracy: 0.9246 - val_loss: 0.3389 - val_accuracy: 0.8897\n",
            "Epoch 100/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.2025 - accuracy: 0.9261 - val_loss: 0.3367 - val_accuracy: 0.8904\n",
            "Epoch 101/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1997 - accuracy: 0.9273 - val_loss: 0.3434 - val_accuracy: 0.8914\n",
            "Epoch 102/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.2041 - accuracy: 0.9256 - val_loss: 0.3386 - val_accuracy: 0.8932\n",
            "Epoch 103/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.2022 - accuracy: 0.9270 - val_loss: 0.3323 - val_accuracy: 0.8937\n",
            "Epoch 104/500\n",
            "48000/48000 [==============================] - 6s 118us/sample - loss: 0.1985 - accuracy: 0.9273 - val_loss: 0.3553 - val_accuracy: 0.8871\n",
            "Epoch 105/500\n",
            "48000/48000 [==============================] - 6s 116us/sample - loss: 0.2030 - accuracy: 0.9251 - val_loss: 0.3364 - val_accuracy: 0.8910\n",
            "Epoch 106/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.2016 - accuracy: 0.9271 - val_loss: 0.3386 - val_accuracy: 0.8923\n",
            "Epoch 107/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1992 - accuracy: 0.9284 - val_loss: 0.3400 - val_accuracy: 0.8921\n",
            "Epoch 108/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1983 - accuracy: 0.9272 - val_loss: 0.3376 - val_accuracy: 0.8930\n",
            "Epoch 109/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1956 - accuracy: 0.9296 - val_loss: 0.3429 - val_accuracy: 0.8904\n",
            "Epoch 110/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1933 - accuracy: 0.9303 - val_loss: 0.3400 - val_accuracy: 0.8928\n",
            "Epoch 111/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.2015 - accuracy: 0.9265 - val_loss: 0.3406 - val_accuracy: 0.8934\n",
            "Epoch 112/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1956 - accuracy: 0.9291 - val_loss: 0.3365 - val_accuracy: 0.8936\n",
            "Epoch 113/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1944 - accuracy: 0.9295 - val_loss: 0.3364 - val_accuracy: 0.8928\n",
            "Epoch 114/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1955 - accuracy: 0.9297 - val_loss: 0.3428 - val_accuracy: 0.8907\n",
            "Epoch 115/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1945 - accuracy: 0.9297 - val_loss: 0.3461 - val_accuracy: 0.8913\n",
            "Epoch 116/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1939 - accuracy: 0.9301 - val_loss: 0.3470 - val_accuracy: 0.8904\n",
            "Epoch 117/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1918 - accuracy: 0.9301 - val_loss: 0.3408 - val_accuracy: 0.8904\n",
            "Epoch 118/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1940 - accuracy: 0.9305 - val_loss: 0.3405 - val_accuracy: 0.8923\n",
            "Epoch 119/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1896 - accuracy: 0.9308 - val_loss: 0.3428 - val_accuracy: 0.8920\n",
            "Epoch 120/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1887 - accuracy: 0.9317 - val_loss: 0.3416 - val_accuracy: 0.8919\n",
            "Epoch 121/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1904 - accuracy: 0.9311 - val_loss: 0.3565 - val_accuracy: 0.8906\n",
            "Epoch 122/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1908 - accuracy: 0.9302 - val_loss: 0.3497 - val_accuracy: 0.8908\n",
            "Epoch 123/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1907 - accuracy: 0.9319 - val_loss: 0.3460 - val_accuracy: 0.8932\n",
            "Epoch 124/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1936 - accuracy: 0.9291 - val_loss: 0.3395 - val_accuracy: 0.8898\n",
            "Epoch 125/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1942 - accuracy: 0.9302 - val_loss: 0.3484 - val_accuracy: 0.8887\n",
            "Epoch 126/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1898 - accuracy: 0.9316 - val_loss: 0.3486 - val_accuracy: 0.8894\n",
            "Epoch 127/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1911 - accuracy: 0.9300 - val_loss: 0.3453 - val_accuracy: 0.8900\n",
            "Epoch 128/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1906 - accuracy: 0.9302 - val_loss: 0.3358 - val_accuracy: 0.8917\n",
            "Epoch 129/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1870 - accuracy: 0.9332 - val_loss: 0.3427 - val_accuracy: 0.8927\n",
            "Epoch 130/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1929 - accuracy: 0.9307 - val_loss: 0.3548 - val_accuracy: 0.8910\n",
            "Epoch 131/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1960 - accuracy: 0.9296 - val_loss: 0.3488 - val_accuracy: 0.8903\n",
            "Epoch 132/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1882 - accuracy: 0.9317 - val_loss: 0.3503 - val_accuracy: 0.8926\n",
            "Epoch 133/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1901 - accuracy: 0.9303 - val_loss: 0.3416 - val_accuracy: 0.8921\n",
            "Epoch 134/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1871 - accuracy: 0.9336 - val_loss: 0.3577 - val_accuracy: 0.8907\n",
            "Epoch 135/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1881 - accuracy: 0.9306 - val_loss: 0.3414 - val_accuracy: 0.8910\n",
            "Epoch 136/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1844 - accuracy: 0.9331 - val_loss: 0.3464 - val_accuracy: 0.8913\n",
            "Epoch 137/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1839 - accuracy: 0.9335 - val_loss: 0.3611 - val_accuracy: 0.8883\n",
            "Epoch 138/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1875 - accuracy: 0.9324 - val_loss: 0.3526 - val_accuracy: 0.8905\n",
            "Epoch 139/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1849 - accuracy: 0.9326 - val_loss: 0.3473 - val_accuracy: 0.8928\n",
            "Epoch 140/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1857 - accuracy: 0.9337 - val_loss: 0.3509 - val_accuracy: 0.8925\n",
            "Epoch 141/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1886 - accuracy: 0.9311 - val_loss: 0.3636 - val_accuracy: 0.8903\n",
            "Epoch 142/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1834 - accuracy: 0.9339 - val_loss: 0.3507 - val_accuracy: 0.8914\n",
            "Epoch 143/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1806 - accuracy: 0.9355 - val_loss: 0.3516 - val_accuracy: 0.8923\n",
            "Epoch 144/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1865 - accuracy: 0.9331 - val_loss: 0.3492 - val_accuracy: 0.8923\n",
            "Epoch 145/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1808 - accuracy: 0.9346 - val_loss: 0.3545 - val_accuracy: 0.8898\n",
            "Epoch 146/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1837 - accuracy: 0.9337 - val_loss: 0.3480 - val_accuracy: 0.8927\n",
            "Epoch 147/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1855 - accuracy: 0.9320 - val_loss: 0.3416 - val_accuracy: 0.8933\n",
            "Epoch 148/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1795 - accuracy: 0.9352 - val_loss: 0.3599 - val_accuracy: 0.8914\n",
            "Epoch 149/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1801 - accuracy: 0.9347 - val_loss: 0.3512 - val_accuracy: 0.8938\n",
            "Epoch 150/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1831 - accuracy: 0.9335 - val_loss: 0.3576 - val_accuracy: 0.8905\n",
            "Epoch 151/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1820 - accuracy: 0.9346 - val_loss: 0.3498 - val_accuracy: 0.8912\n",
            "Epoch 152/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1781 - accuracy: 0.9363 - val_loss: 0.3535 - val_accuracy: 0.8914\n",
            "Epoch 153/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1800 - accuracy: 0.9350 - val_loss: 0.3475 - val_accuracy: 0.8923\n",
            "Epoch 154/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1801 - accuracy: 0.9352 - val_loss: 0.3589 - val_accuracy: 0.8914\n",
            "Epoch 155/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1777 - accuracy: 0.9354 - val_loss: 0.3557 - val_accuracy: 0.8914\n",
            "Epoch 156/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1737 - accuracy: 0.9378 - val_loss: 0.3565 - val_accuracy: 0.8936\n",
            "Epoch 157/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1821 - accuracy: 0.9340 - val_loss: 0.3448 - val_accuracy: 0.8924\n",
            "Epoch 158/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1790 - accuracy: 0.9358 - val_loss: 0.3505 - val_accuracy: 0.8894\n",
            "Epoch 159/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1778 - accuracy: 0.9357 - val_loss: 0.3527 - val_accuracy: 0.8925\n",
            "Epoch 160/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1777 - accuracy: 0.9362 - val_loss: 0.3530 - val_accuracy: 0.8902\n",
            "Epoch 161/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1793 - accuracy: 0.9354 - val_loss: 0.3492 - val_accuracy: 0.8917\n",
            "Epoch 162/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1772 - accuracy: 0.9362 - val_loss: 0.3559 - val_accuracy: 0.8866\n",
            "Epoch 163/500\n",
            "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1769 - accuracy: 0.9368 - val_loss: 0.3539 - val_accuracy: 0.8913\n",
            "Epoch 164/500\n",
            "48000/48000 [==============================] - 5s 106us/sample - loss: 0.1792 - accuracy: 0.9359 - val_loss: 0.3593 - val_accuracy: 0.8931\n",
            "Epoch 165/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1705 - accuracy: 0.9395 - val_loss: 0.3585 - val_accuracy: 0.8932\n",
            "Epoch 166/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1758 - accuracy: 0.9373 - val_loss: 0.3610 - val_accuracy: 0.8911\n",
            "Epoch 167/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1736 - accuracy: 0.9372 - val_loss: 0.3580 - val_accuracy: 0.8879\n",
            "Epoch 168/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1755 - accuracy: 0.9373 - val_loss: 0.3584 - val_accuracy: 0.8907\n",
            "Epoch 169/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1732 - accuracy: 0.9374 - val_loss: 0.3716 - val_accuracy: 0.8909\n",
            "Epoch 170/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1734 - accuracy: 0.9381 - val_loss: 0.3633 - val_accuracy: 0.8917\n",
            "Epoch 171/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1727 - accuracy: 0.9373 - val_loss: 0.3552 - val_accuracy: 0.8906\n",
            "Epoch 172/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1743 - accuracy: 0.9375 - val_loss: 0.3653 - val_accuracy: 0.8904\n",
            "Epoch 173/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1705 - accuracy: 0.9395 - val_loss: 0.3605 - val_accuracy: 0.8921\n",
            "Epoch 174/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1734 - accuracy: 0.9370 - val_loss: 0.3651 - val_accuracy: 0.8904\n",
            "Epoch 175/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1714 - accuracy: 0.9396 - val_loss: 0.3630 - val_accuracy: 0.8912\n",
            "Epoch 176/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1723 - accuracy: 0.9369 - val_loss: 0.3607 - val_accuracy: 0.8923\n",
            "Epoch 177/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1729 - accuracy: 0.9366 - val_loss: 0.3656 - val_accuracy: 0.8898\n",
            "Epoch 178/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1728 - accuracy: 0.9369 - val_loss: 0.3646 - val_accuracy: 0.8898\n",
            "Epoch 179/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1690 - accuracy: 0.9399 - val_loss: 0.3630 - val_accuracy: 0.8949\n",
            "Epoch 180/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1683 - accuracy: 0.9393 - val_loss: 0.3662 - val_accuracy: 0.8924\n",
            "Epoch 181/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1691 - accuracy: 0.9392 - val_loss: 0.3657 - val_accuracy: 0.8911\n",
            "Epoch 182/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1718 - accuracy: 0.9379 - val_loss: 0.3584 - val_accuracy: 0.8937\n",
            "Epoch 183/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1709 - accuracy: 0.9390 - val_loss: 0.3589 - val_accuracy: 0.8912\n",
            "Epoch 184/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1736 - accuracy: 0.9378 - val_loss: 0.3604 - val_accuracy: 0.8914\n",
            "Epoch 185/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1726 - accuracy: 0.9382 - val_loss: 0.3656 - val_accuracy: 0.8921\n",
            "Epoch 186/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1721 - accuracy: 0.9369 - val_loss: 0.3671 - val_accuracy: 0.8889\n",
            "Epoch 187/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1740 - accuracy: 0.9379 - val_loss: 0.3626 - val_accuracy: 0.8905\n",
            "Epoch 188/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1697 - accuracy: 0.9389 - val_loss: 0.3601 - val_accuracy: 0.8916\n",
            "Epoch 189/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1689 - accuracy: 0.9392 - val_loss: 0.3684 - val_accuracy: 0.8903\n",
            "Epoch 190/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1692 - accuracy: 0.9395 - val_loss: 0.3656 - val_accuracy: 0.8906\n",
            "Epoch 191/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1658 - accuracy: 0.9408 - val_loss: 0.3682 - val_accuracy: 0.8915\n",
            "Epoch 192/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1667 - accuracy: 0.9383 - val_loss: 0.3707 - val_accuracy: 0.8904\n",
            "Epoch 193/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1635 - accuracy: 0.9410 - val_loss: 0.3679 - val_accuracy: 0.8925\n",
            "Epoch 194/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1732 - accuracy: 0.9369 - val_loss: 0.3656 - val_accuracy: 0.8924\n",
            "Epoch 195/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1639 - accuracy: 0.9404 - val_loss: 0.3708 - val_accuracy: 0.8896\n",
            "Epoch 196/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1705 - accuracy: 0.9391 - val_loss: 0.3580 - val_accuracy: 0.8930\n",
            "Epoch 197/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1698 - accuracy: 0.9389 - val_loss: 0.3588 - val_accuracy: 0.8920\n",
            "Epoch 198/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1672 - accuracy: 0.9406 - val_loss: 0.3690 - val_accuracy: 0.8913\n",
            "Epoch 199/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1650 - accuracy: 0.9400 - val_loss: 0.3687 - val_accuracy: 0.8909\n",
            "Epoch 200/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1671 - accuracy: 0.9401 - val_loss: 0.3624 - val_accuracy: 0.8924\n",
            "Epoch 201/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1640 - accuracy: 0.9411 - val_loss: 0.3769 - val_accuracy: 0.8905\n",
            "Epoch 202/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1664 - accuracy: 0.9393 - val_loss: 0.3707 - val_accuracy: 0.8892\n",
            "Epoch 203/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1680 - accuracy: 0.9398 - val_loss: 0.3630 - val_accuracy: 0.8925\n",
            "Epoch 204/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1671 - accuracy: 0.9393 - val_loss: 0.3646 - val_accuracy: 0.8913\n",
            "Epoch 205/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1653 - accuracy: 0.9406 - val_loss: 0.3847 - val_accuracy: 0.8893\n",
            "Epoch 206/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1648 - accuracy: 0.9400 - val_loss: 0.3663 - val_accuracy: 0.8907\n",
            "Epoch 207/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1722 - accuracy: 0.9379 - val_loss: 0.3720 - val_accuracy: 0.8909\n",
            "Epoch 208/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1626 - accuracy: 0.9414 - val_loss: 0.3703 - val_accuracy: 0.8927\n",
            "Epoch 209/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1650 - accuracy: 0.9409 - val_loss: 0.3753 - val_accuracy: 0.8932\n",
            "Epoch 210/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1634 - accuracy: 0.9409 - val_loss: 0.3691 - val_accuracy: 0.8934\n",
            "Epoch 211/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1670 - accuracy: 0.9398 - val_loss: 0.3761 - val_accuracy: 0.8923\n",
            "Epoch 212/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1617 - accuracy: 0.9416 - val_loss: 0.3664 - val_accuracy: 0.8911\n",
            "Epoch 213/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1674 - accuracy: 0.9399 - val_loss: 0.3711 - val_accuracy: 0.8903\n",
            "Epoch 214/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1612 - accuracy: 0.9419 - val_loss: 0.3748 - val_accuracy: 0.8909\n",
            "Epoch 215/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1631 - accuracy: 0.9409 - val_loss: 0.3729 - val_accuracy: 0.8903\n",
            "Epoch 216/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1624 - accuracy: 0.9414 - val_loss: 0.3799 - val_accuracy: 0.8901\n",
            "Epoch 217/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1602 - accuracy: 0.9418 - val_loss: 0.3721 - val_accuracy: 0.8892\n",
            "Epoch 218/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1643 - accuracy: 0.9412 - val_loss: 0.3749 - val_accuracy: 0.8912\n",
            "Epoch 219/500\n",
            "48000/48000 [==============================] - 6s 116us/sample - loss: 0.1597 - accuracy: 0.9416 - val_loss: 0.3728 - val_accuracy: 0.8891\n",
            "Epoch 220/500\n",
            "48000/48000 [==============================] - 6s 124us/sample - loss: 0.1638 - accuracy: 0.9417 - val_loss: 0.3682 - val_accuracy: 0.8901\n",
            "Epoch 221/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1643 - accuracy: 0.9419 - val_loss: 0.3697 - val_accuracy: 0.8914\n",
            "Epoch 222/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1651 - accuracy: 0.9405 - val_loss: 0.3666 - val_accuracy: 0.8914\n",
            "Epoch 223/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1614 - accuracy: 0.9420 - val_loss: 0.3795 - val_accuracy: 0.8893\n",
            "Epoch 224/500\n",
            "48000/48000 [==============================] - 6s 123us/sample - loss: 0.1618 - accuracy: 0.9417 - val_loss: 0.3785 - val_accuracy: 0.8855\n",
            "Epoch 225/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1628 - accuracy: 0.9414 - val_loss: 0.3713 - val_accuracy: 0.8906\n",
            "Epoch 226/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1605 - accuracy: 0.9431 - val_loss: 0.3732 - val_accuracy: 0.8919\n",
            "Epoch 227/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1617 - accuracy: 0.9430 - val_loss: 0.3847 - val_accuracy: 0.8898\n",
            "Epoch 228/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1628 - accuracy: 0.9411 - val_loss: 0.3746 - val_accuracy: 0.8864\n",
            "Epoch 229/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1606 - accuracy: 0.9430 - val_loss: 0.3741 - val_accuracy: 0.8901\n",
            "Epoch 230/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1611 - accuracy: 0.9427 - val_loss: 0.3680 - val_accuracy: 0.8900\n",
            "Epoch 231/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1603 - accuracy: 0.9433 - val_loss: 0.3761 - val_accuracy: 0.8912\n",
            "Epoch 232/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1590 - accuracy: 0.9433 - val_loss: 0.3737 - val_accuracy: 0.8916\n",
            "Epoch 233/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1573 - accuracy: 0.9442 - val_loss: 0.3755 - val_accuracy: 0.8922\n",
            "Epoch 234/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1566 - accuracy: 0.9441 - val_loss: 0.3912 - val_accuracy: 0.8869\n",
            "Epoch 235/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1590 - accuracy: 0.9440 - val_loss: 0.3805 - val_accuracy: 0.8897\n",
            "Epoch 236/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.3748 - val_accuracy: 0.8928\n",
            "Epoch 237/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1595 - accuracy: 0.9420 - val_loss: 0.3727 - val_accuracy: 0.8907\n",
            "Epoch 238/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1563 - accuracy: 0.9441 - val_loss: 0.3804 - val_accuracy: 0.8914\n",
            "Epoch 239/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1582 - accuracy: 0.9433 - val_loss: 0.3940 - val_accuracy: 0.8878\n",
            "Epoch 240/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1599 - accuracy: 0.9428 - val_loss: 0.3779 - val_accuracy: 0.8903\n",
            "Epoch 241/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1537 - accuracy: 0.9466 - val_loss: 0.3843 - val_accuracy: 0.8908\n",
            "Epoch 242/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1573 - accuracy: 0.9423 - val_loss: 0.3709 - val_accuracy: 0.8909\n",
            "Epoch 243/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1543 - accuracy: 0.9455 - val_loss: 0.3718 - val_accuracy: 0.8907\n",
            "Epoch 244/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1571 - accuracy: 0.9432 - val_loss: 0.3767 - val_accuracy: 0.8915\n",
            "Epoch 245/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1558 - accuracy: 0.9449 - val_loss: 0.3843 - val_accuracy: 0.8876\n",
            "Epoch 246/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1569 - accuracy: 0.9431 - val_loss: 0.3817 - val_accuracy: 0.8892\n",
            "Epoch 247/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1531 - accuracy: 0.9457 - val_loss: 0.3805 - val_accuracy: 0.8915\n",
            "Epoch 248/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1542 - accuracy: 0.9447 - val_loss: 0.3757 - val_accuracy: 0.8907\n",
            "Epoch 249/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1550 - accuracy: 0.9442 - val_loss: 0.3817 - val_accuracy: 0.8919\n",
            "Epoch 250/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1551 - accuracy: 0.9448 - val_loss: 0.3813 - val_accuracy: 0.8895\n",
            "Epoch 251/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1542 - accuracy: 0.9451 - val_loss: 0.3791 - val_accuracy: 0.8907\n",
            "Epoch 252/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1534 - accuracy: 0.9446 - val_loss: 0.3830 - val_accuracy: 0.8903\n",
            "Epoch 253/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1524 - accuracy: 0.9455 - val_loss: 0.3878 - val_accuracy: 0.8880\n",
            "Epoch 254/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1529 - accuracy: 0.9467 - val_loss: 0.3906 - val_accuracy: 0.8923\n",
            "Epoch 255/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1513 - accuracy: 0.9460 - val_loss: 0.3866 - val_accuracy: 0.8890\n",
            "Epoch 256/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1526 - accuracy: 0.9460 - val_loss: 0.3869 - val_accuracy: 0.8901\n",
            "Epoch 257/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1550 - accuracy: 0.9439 - val_loss: 0.3854 - val_accuracy: 0.8888\n",
            "Epoch 258/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1544 - accuracy: 0.9440 - val_loss: 0.3950 - val_accuracy: 0.8891\n",
            "Epoch 259/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1543 - accuracy: 0.9452 - val_loss: 0.3876 - val_accuracy: 0.8905\n",
            "Epoch 260/500\n",
            "48000/48000 [==============================] - 6s 122us/sample - loss: 0.1536 - accuracy: 0.9445 - val_loss: 0.3882 - val_accuracy: 0.8895\n",
            "Epoch 261/500\n",
            "48000/48000 [==============================] - 6s 118us/sample - loss: 0.1535 - accuracy: 0.9451 - val_loss: 0.3825 - val_accuracy: 0.8920\n",
            "Epoch 262/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1520 - accuracy: 0.9451 - val_loss: 0.3738 - val_accuracy: 0.8919\n",
            "Epoch 263/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1507 - accuracy: 0.9457 - val_loss: 0.3901 - val_accuracy: 0.8926\n",
            "Epoch 264/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1511 - accuracy: 0.9456 - val_loss: 0.3892 - val_accuracy: 0.8895\n",
            "Epoch 265/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1537 - accuracy: 0.9454 - val_loss: 0.3934 - val_accuracy: 0.8864\n",
            "Epoch 266/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1532 - accuracy: 0.9457 - val_loss: 0.3997 - val_accuracy: 0.8883\n",
            "Epoch 267/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1585 - accuracy: 0.9431 - val_loss: 0.3768 - val_accuracy: 0.8906\n",
            "Epoch 268/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1580 - accuracy: 0.9439 - val_loss: 0.3780 - val_accuracy: 0.8907\n",
            "Epoch 269/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1515 - accuracy: 0.9463 - val_loss: 0.3832 - val_accuracy: 0.8888\n",
            "Epoch 270/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1551 - accuracy: 0.9443 - val_loss: 0.3922 - val_accuracy: 0.8891\n",
            "Epoch 271/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1535 - accuracy: 0.9455 - val_loss: 0.3859 - val_accuracy: 0.8863\n",
            "Epoch 272/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1513 - accuracy: 0.9451 - val_loss: 0.3955 - val_accuracy: 0.8886\n",
            "Epoch 273/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1497 - accuracy: 0.9464 - val_loss: 0.3807 - val_accuracy: 0.8914\n",
            "Epoch 274/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1548 - accuracy: 0.9452 - val_loss: 0.3897 - val_accuracy: 0.8899\n",
            "Epoch 275/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1503 - accuracy: 0.9470 - val_loss: 0.3892 - val_accuracy: 0.8900\n",
            "Epoch 276/500\n",
            "48000/48000 [==============================] - 6s 116us/sample - loss: 0.1509 - accuracy: 0.9461 - val_loss: 0.3819 - val_accuracy: 0.8906\n",
            "Epoch 277/500\n",
            "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1527 - accuracy: 0.9440 - val_loss: 0.3871 - val_accuracy: 0.8889\n",
            "Epoch 278/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1491 - accuracy: 0.9468 - val_loss: 0.3882 - val_accuracy: 0.8913\n",
            "Epoch 279/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1526 - accuracy: 0.9450 - val_loss: 0.3856 - val_accuracy: 0.8907\n",
            "Epoch 280/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1495 - accuracy: 0.9462 - val_loss: 0.3927 - val_accuracy: 0.8888\n",
            "Epoch 281/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1531 - accuracy: 0.9460 - val_loss: 0.3873 - val_accuracy: 0.8903\n",
            "Epoch 282/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.3795 - val_accuracy: 0.8928\n",
            "Epoch 283/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1496 - accuracy: 0.9468 - val_loss: 0.3827 - val_accuracy: 0.8907\n",
            "Epoch 284/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1495 - accuracy: 0.9460 - val_loss: 0.3887 - val_accuracy: 0.8903\n",
            "Epoch 285/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1505 - accuracy: 0.9461 - val_loss: 0.3861 - val_accuracy: 0.8900\n",
            "Epoch 286/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1543 - accuracy: 0.9453 - val_loss: 0.3966 - val_accuracy: 0.8903\n",
            "Epoch 287/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1500 - accuracy: 0.9468 - val_loss: 0.4006 - val_accuracy: 0.8869\n",
            "Epoch 288/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1431 - accuracy: 0.9495 - val_loss: 0.3908 - val_accuracy: 0.8902\n",
            "Epoch 289/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1509 - accuracy: 0.9459 - val_loss: 0.3997 - val_accuracy: 0.8895\n",
            "Epoch 290/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1502 - accuracy: 0.9459 - val_loss: 0.3898 - val_accuracy: 0.8913\n",
            "Epoch 291/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1462 - accuracy: 0.9480 - val_loss: 0.3884 - val_accuracy: 0.8923\n",
            "Epoch 292/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1497 - accuracy: 0.9470 - val_loss: 0.3990 - val_accuracy: 0.8859\n",
            "Epoch 293/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1503 - accuracy: 0.9473 - val_loss: 0.3884 - val_accuracy: 0.8894\n",
            "Epoch 294/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1521 - accuracy: 0.9456 - val_loss: 0.3852 - val_accuracy: 0.8902\n",
            "Epoch 295/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1442 - accuracy: 0.9488 - val_loss: 0.3965 - val_accuracy: 0.8899\n",
            "Epoch 296/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1499 - accuracy: 0.9460 - val_loss: 0.3954 - val_accuracy: 0.8909\n",
            "Epoch 297/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1541 - accuracy: 0.9454 - val_loss: 0.3893 - val_accuracy: 0.8901\n",
            "Epoch 298/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1455 - accuracy: 0.9477 - val_loss: 0.3918 - val_accuracy: 0.8898\n",
            "Epoch 299/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1460 - accuracy: 0.9481 - val_loss: 0.3926 - val_accuracy: 0.8910\n",
            "Epoch 300/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1465 - accuracy: 0.9485 - val_loss: 0.3855 - val_accuracy: 0.8907\n",
            "Epoch 301/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1524 - accuracy: 0.9454 - val_loss: 0.3881 - val_accuracy: 0.8905\n",
            "Epoch 302/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1488 - accuracy: 0.9472 - val_loss: 0.3916 - val_accuracy: 0.8893\n",
            "Epoch 303/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1486 - accuracy: 0.9468 - val_loss: 0.3968 - val_accuracy: 0.8878\n",
            "Epoch 304/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1443 - accuracy: 0.9485 - val_loss: 0.3921 - val_accuracy: 0.8901\n",
            "Epoch 305/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1455 - accuracy: 0.9482 - val_loss: 0.3909 - val_accuracy: 0.8922\n",
            "Epoch 306/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1461 - accuracy: 0.9474 - val_loss: 0.3935 - val_accuracy: 0.8913\n",
            "Epoch 307/500\n",
            "48000/48000 [==============================] - 5s 115us/sample - loss: 0.1490 - accuracy: 0.9463 - val_loss: 0.3910 - val_accuracy: 0.8906\n",
            "Epoch 308/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1495 - accuracy: 0.9467 - val_loss: 0.3893 - val_accuracy: 0.8905\n",
            "Epoch 309/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1462 - accuracy: 0.9476 - val_loss: 0.3910 - val_accuracy: 0.8910\n",
            "Epoch 310/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1428 - accuracy: 0.9493 - val_loss: 0.3991 - val_accuracy: 0.8896\n",
            "Epoch 311/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1473 - accuracy: 0.9477 - val_loss: 0.3986 - val_accuracy: 0.8899\n",
            "Epoch 312/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1473 - accuracy: 0.9477 - val_loss: 0.3941 - val_accuracy: 0.8893\n",
            "Epoch 313/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1439 - accuracy: 0.9481 - val_loss: 0.3953 - val_accuracy: 0.8882\n",
            "Epoch 314/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1448 - accuracy: 0.9482 - val_loss: 0.3916 - val_accuracy: 0.8911\n",
            "Epoch 315/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1430 - accuracy: 0.9496 - val_loss: 0.3947 - val_accuracy: 0.8901\n",
            "Epoch 316/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1445 - accuracy: 0.9491 - val_loss: 0.3998 - val_accuracy: 0.8899\n",
            "Epoch 317/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1436 - accuracy: 0.9482 - val_loss: 0.3886 - val_accuracy: 0.8937\n",
            "Epoch 318/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1401 - accuracy: 0.9510 - val_loss: 0.3905 - val_accuracy: 0.8907\n",
            "Epoch 319/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1442 - accuracy: 0.9479 - val_loss: 0.3876 - val_accuracy: 0.8903\n",
            "Epoch 320/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1465 - accuracy: 0.9476 - val_loss: 0.3869 - val_accuracy: 0.8913\n",
            "Epoch 321/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1487 - accuracy: 0.9475 - val_loss: 0.3873 - val_accuracy: 0.8914\n",
            "Epoch 322/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1412 - accuracy: 0.9492 - val_loss: 0.4005 - val_accuracy: 0.8901\n",
            "Epoch 323/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1432 - accuracy: 0.9486 - val_loss: 0.3955 - val_accuracy: 0.8898\n",
            "Epoch 324/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1449 - accuracy: 0.9492 - val_loss: 0.3907 - val_accuracy: 0.8891\n",
            "Epoch 325/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1443 - accuracy: 0.9484 - val_loss: 0.4000 - val_accuracy: 0.8907\n",
            "Epoch 326/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1390 - accuracy: 0.9506 - val_loss: 0.4005 - val_accuracy: 0.8906\n",
            "Epoch 327/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1426 - accuracy: 0.9497 - val_loss: 0.3972 - val_accuracy: 0.8893\n",
            "Epoch 328/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1434 - accuracy: 0.9494 - val_loss: 0.3948 - val_accuracy: 0.8917\n",
            "Epoch 329/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1428 - accuracy: 0.9497 - val_loss: 0.3938 - val_accuracy: 0.8920\n",
            "Epoch 330/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1370 - accuracy: 0.9511 - val_loss: 0.4056 - val_accuracy: 0.8897\n",
            "Epoch 331/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1418 - accuracy: 0.9491 - val_loss: 0.3989 - val_accuracy: 0.8894\n",
            "Epoch 332/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1396 - accuracy: 0.9505 - val_loss: 0.3993 - val_accuracy: 0.8882\n",
            "Epoch 333/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1419 - accuracy: 0.9503 - val_loss: 0.3997 - val_accuracy: 0.8919\n",
            "Epoch 334/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1400 - accuracy: 0.9507 - val_loss: 0.3951 - val_accuracy: 0.8897\n",
            "Epoch 335/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1382 - accuracy: 0.9519 - val_loss: 0.4007 - val_accuracy: 0.8928\n",
            "Epoch 336/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1400 - accuracy: 0.9506 - val_loss: 0.4018 - val_accuracy: 0.8930\n",
            "Epoch 337/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1394 - accuracy: 0.9503 - val_loss: 0.4011 - val_accuracy: 0.8897\n",
            "Epoch 338/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1367 - accuracy: 0.9510 - val_loss: 0.4063 - val_accuracy: 0.8898\n",
            "Epoch 339/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1399 - accuracy: 0.9509 - val_loss: 0.3958 - val_accuracy: 0.8902\n",
            "Epoch 340/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1361 - accuracy: 0.9524 - val_loss: 0.4040 - val_accuracy: 0.8903\n",
            "Epoch 341/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1388 - accuracy: 0.9500 - val_loss: 0.4030 - val_accuracy: 0.8901\n",
            "Epoch 342/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1413 - accuracy: 0.9500 - val_loss: 0.4113 - val_accuracy: 0.8903\n",
            "Epoch 343/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1377 - accuracy: 0.9508 - val_loss: 0.3968 - val_accuracy: 0.8903\n",
            "Epoch 344/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1413 - accuracy: 0.9507 - val_loss: 0.4044 - val_accuracy: 0.8903\n",
            "Epoch 345/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1418 - accuracy: 0.9502 - val_loss: 0.3974 - val_accuracy: 0.8908\n",
            "Epoch 346/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1451 - accuracy: 0.9488 - val_loss: 0.3904 - val_accuracy: 0.8911\n",
            "Epoch 347/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1382 - accuracy: 0.9519 - val_loss: 0.3996 - val_accuracy: 0.8929\n",
            "Epoch 348/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1383 - accuracy: 0.9510 - val_loss: 0.4011 - val_accuracy: 0.8918\n",
            "Epoch 349/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1400 - accuracy: 0.9505 - val_loss: 0.4019 - val_accuracy: 0.8909\n",
            "Epoch 350/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1393 - accuracy: 0.9506 - val_loss: 0.4101 - val_accuracy: 0.8906\n",
            "Epoch 351/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1360 - accuracy: 0.9524 - val_loss: 0.4040 - val_accuracy: 0.8880\n",
            "Epoch 352/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1420 - accuracy: 0.9500 - val_loss: 0.3980 - val_accuracy: 0.8916\n",
            "Epoch 353/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1368 - accuracy: 0.9518 - val_loss: 0.4070 - val_accuracy: 0.8884\n",
            "Epoch 354/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1361 - accuracy: 0.9528 - val_loss: 0.4038 - val_accuracy: 0.8900\n",
            "Epoch 355/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1351 - accuracy: 0.9527 - val_loss: 0.4053 - val_accuracy: 0.8888\n",
            "Epoch 356/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1346 - accuracy: 0.9536 - val_loss: 0.4048 - val_accuracy: 0.8874\n",
            "Epoch 357/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1364 - accuracy: 0.9509 - val_loss: 0.4041 - val_accuracy: 0.8889\n",
            "Epoch 358/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1376 - accuracy: 0.9529 - val_loss: 0.4035 - val_accuracy: 0.8882\n",
            "Epoch 359/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1409 - accuracy: 0.9500 - val_loss: 0.3960 - val_accuracy: 0.8905\n",
            "Epoch 360/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1339 - accuracy: 0.9523 - val_loss: 0.3932 - val_accuracy: 0.8905\n",
            "Epoch 361/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1380 - accuracy: 0.9506 - val_loss: 0.4008 - val_accuracy: 0.8867\n",
            "Epoch 362/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1367 - accuracy: 0.9522 - val_loss: 0.4104 - val_accuracy: 0.8892\n",
            "Epoch 363/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1398 - accuracy: 0.9498 - val_loss: 0.3981 - val_accuracy: 0.8911\n",
            "Epoch 364/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1352 - accuracy: 0.9516 - val_loss: 0.4037 - val_accuracy: 0.8889\n",
            "Epoch 365/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1369 - accuracy: 0.9524 - val_loss: 0.4091 - val_accuracy: 0.8898\n",
            "Epoch 366/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1364 - accuracy: 0.9514 - val_loss: 0.3978 - val_accuracy: 0.8906\n",
            "Epoch 367/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1320 - accuracy: 0.9528 - val_loss: 0.4112 - val_accuracy: 0.8846\n",
            "Epoch 368/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1341 - accuracy: 0.9523 - val_loss: 0.4051 - val_accuracy: 0.8891\n",
            "Epoch 369/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1389 - accuracy: 0.9498 - val_loss: 0.3986 - val_accuracy: 0.8898\n",
            "Epoch 370/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1377 - accuracy: 0.9520 - val_loss: 0.3959 - val_accuracy: 0.8899\n",
            "Epoch 371/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1368 - accuracy: 0.9521 - val_loss: 0.4043 - val_accuracy: 0.8883\n",
            "Epoch 372/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1398 - accuracy: 0.9501 - val_loss: 0.4015 - val_accuracy: 0.8885\n",
            "Epoch 373/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1339 - accuracy: 0.9530 - val_loss: 0.4062 - val_accuracy: 0.8908\n",
            "Epoch 374/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1387 - accuracy: 0.9513 - val_loss: 0.4015 - val_accuracy: 0.8863\n",
            "Epoch 375/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1364 - accuracy: 0.9525 - val_loss: 0.4002 - val_accuracy: 0.8870\n",
            "Epoch 376/500\n",
            "48000/48000 [==============================] - 6s 115us/sample - loss: 0.1319 - accuracy: 0.9530 - val_loss: 0.3993 - val_accuracy: 0.8907\n",
            "Epoch 377/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1331 - accuracy: 0.9519 - val_loss: 0.4066 - val_accuracy: 0.8888\n",
            "Epoch 378/500\n",
            "48000/48000 [==============================] - 6s 116us/sample - loss: 0.1356 - accuracy: 0.9517 - val_loss: 0.3951 - val_accuracy: 0.8900\n",
            "Epoch 379/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1351 - accuracy: 0.9519 - val_loss: 0.3917 - val_accuracy: 0.8924\n",
            "Epoch 380/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1346 - accuracy: 0.9519 - val_loss: 0.4092 - val_accuracy: 0.8882\n",
            "Epoch 381/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1354 - accuracy: 0.9522 - val_loss: 0.4158 - val_accuracy: 0.8853\n",
            "Epoch 382/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1371 - accuracy: 0.9513 - val_loss: 0.3980 - val_accuracy: 0.8895\n",
            "Epoch 383/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1344 - accuracy: 0.9523 - val_loss: 0.4080 - val_accuracy: 0.8907\n",
            "Epoch 384/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1329 - accuracy: 0.9525 - val_loss: 0.4052 - val_accuracy: 0.8894\n",
            "Epoch 385/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1338 - accuracy: 0.9533 - val_loss: 0.4082 - val_accuracy: 0.8885\n",
            "Epoch 386/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1382 - accuracy: 0.9502 - val_loss: 0.4028 - val_accuracy: 0.8901\n",
            "Epoch 387/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1319 - accuracy: 0.9531 - val_loss: 0.4017 - val_accuracy: 0.8903\n",
            "Epoch 388/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1353 - accuracy: 0.9525 - val_loss: 0.4180 - val_accuracy: 0.8891\n",
            "Epoch 389/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1324 - accuracy: 0.9538 - val_loss: 0.4040 - val_accuracy: 0.8887\n",
            "Epoch 390/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1341 - accuracy: 0.9529 - val_loss: 0.4087 - val_accuracy: 0.8907\n",
            "Epoch 391/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1350 - accuracy: 0.9520 - val_loss: 0.4033 - val_accuracy: 0.8903\n",
            "Epoch 392/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1307 - accuracy: 0.9535 - val_loss: 0.4103 - val_accuracy: 0.8888\n",
            "Epoch 393/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1335 - accuracy: 0.9529 - val_loss: 0.4044 - val_accuracy: 0.8883\n",
            "Epoch 394/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1345 - accuracy: 0.9516 - val_loss: 0.4128 - val_accuracy: 0.8877\n",
            "Epoch 395/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1340 - accuracy: 0.9528 - val_loss: 0.4000 - val_accuracy: 0.8900\n",
            "Epoch 396/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1330 - accuracy: 0.9534 - val_loss: 0.4056 - val_accuracy: 0.8912\n",
            "Epoch 397/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1321 - accuracy: 0.9530 - val_loss: 0.4169 - val_accuracy: 0.8907\n",
            "Epoch 398/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1308 - accuracy: 0.9533 - val_loss: 0.4098 - val_accuracy: 0.8916\n",
            "Epoch 399/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1304 - accuracy: 0.9545 - val_loss: 0.4121 - val_accuracy: 0.8904\n",
            "Epoch 400/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1316 - accuracy: 0.9535 - val_loss: 0.4161 - val_accuracy: 0.8919\n",
            "Epoch 401/500\n",
            "48000/48000 [==============================] - 5s 114us/sample - loss: 0.1311 - accuracy: 0.9530 - val_loss: 0.4098 - val_accuracy: 0.8900\n",
            "Epoch 402/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1292 - accuracy: 0.9550 - val_loss: 0.4240 - val_accuracy: 0.8906\n",
            "Epoch 403/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1332 - accuracy: 0.9534 - val_loss: 0.4193 - val_accuracy: 0.8892\n",
            "Epoch 404/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1324 - accuracy: 0.9537 - val_loss: 0.4089 - val_accuracy: 0.8873\n",
            "Epoch 405/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1332 - accuracy: 0.9531 - val_loss: 0.4062 - val_accuracy: 0.8882\n",
            "Epoch 406/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1302 - accuracy: 0.9551 - val_loss: 0.4106 - val_accuracy: 0.8898\n",
            "Epoch 407/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1288 - accuracy: 0.9546 - val_loss: 0.4117 - val_accuracy: 0.8901\n",
            "Epoch 408/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1300 - accuracy: 0.9540 - val_loss: 0.4126 - val_accuracy: 0.8914\n",
            "Epoch 409/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1259 - accuracy: 0.9555 - val_loss: 0.4148 - val_accuracy: 0.8904\n",
            "Epoch 410/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1290 - accuracy: 0.9545 - val_loss: 0.4098 - val_accuracy: 0.8898\n",
            "Epoch 411/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1291 - accuracy: 0.9550 - val_loss: 0.4118 - val_accuracy: 0.8909\n",
            "Epoch 412/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1299 - accuracy: 0.9529 - val_loss: 0.4212 - val_accuracy: 0.8866\n",
            "Epoch 413/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1331 - accuracy: 0.9522 - val_loss: 0.4147 - val_accuracy: 0.8887\n",
            "Epoch 414/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1324 - accuracy: 0.9531 - val_loss: 0.4077 - val_accuracy: 0.8919\n",
            "Epoch 415/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1283 - accuracy: 0.9551 - val_loss: 0.4116 - val_accuracy: 0.8886\n",
            "Epoch 416/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1283 - accuracy: 0.9547 - val_loss: 0.4138 - val_accuracy: 0.8901\n",
            "Epoch 417/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1296 - accuracy: 0.9546 - val_loss: 0.4109 - val_accuracy: 0.8885\n",
            "Epoch 418/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1301 - accuracy: 0.9539 - val_loss: 0.4101 - val_accuracy: 0.8903\n",
            "Epoch 419/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1290 - accuracy: 0.9538 - val_loss: 0.4113 - val_accuracy: 0.8898\n",
            "Epoch 420/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1317 - accuracy: 0.9536 - val_loss: 0.4095 - val_accuracy: 0.8932\n",
            "Epoch 421/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1261 - accuracy: 0.9557 - val_loss: 0.4276 - val_accuracy: 0.8881\n",
            "Epoch 422/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1296 - accuracy: 0.9542 - val_loss: 0.4199 - val_accuracy: 0.8907\n",
            "Epoch 423/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1313 - accuracy: 0.9542 - val_loss: 0.4109 - val_accuracy: 0.8915\n",
            "Epoch 424/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1325 - accuracy: 0.9529 - val_loss: 0.4115 - val_accuracy: 0.8893\n",
            "Epoch 425/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1293 - accuracy: 0.9552 - val_loss: 0.4169 - val_accuracy: 0.8902\n",
            "Epoch 426/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1356 - accuracy: 0.9535 - val_loss: 0.4186 - val_accuracy: 0.8917\n",
            "Epoch 427/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1275 - accuracy: 0.9551 - val_loss: 0.4184 - val_accuracy: 0.8906\n",
            "Epoch 428/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1303 - accuracy: 0.9540 - val_loss: 0.4134 - val_accuracy: 0.8893\n",
            "Epoch 429/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1306 - accuracy: 0.9543 - val_loss: 0.4178 - val_accuracy: 0.8888\n",
            "Epoch 430/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1271 - accuracy: 0.9562 - val_loss: 0.4183 - val_accuracy: 0.8911\n",
            "Epoch 431/500\n",
            "48000/48000 [==============================] - 5s 113us/sample - loss: 0.1297 - accuracy: 0.9549 - val_loss: 0.4097 - val_accuracy: 0.8897\n",
            "Epoch 432/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1350 - accuracy: 0.9532 - val_loss: 0.4162 - val_accuracy: 0.8901\n",
            "Epoch 433/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1306 - accuracy: 0.9545 - val_loss: 0.4141 - val_accuracy: 0.8897\n",
            "Epoch 434/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1265 - accuracy: 0.9556 - val_loss: 0.4195 - val_accuracy: 0.8854\n",
            "Epoch 435/500\n",
            "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1275 - accuracy: 0.9550 - val_loss: 0.4244 - val_accuracy: 0.8899\n",
            "Epoch 436/500\n",
            "48000/48000 [==============================] - 6s 118us/sample - loss: 0.1303 - accuracy: 0.9541 - val_loss: 0.4083 - val_accuracy: 0.8876\n",
            "Epoch 437/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1292 - accuracy: 0.9545 - val_loss: 0.4222 - val_accuracy: 0.8900\n",
            "Epoch 438/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1302 - accuracy: 0.9545 - val_loss: 0.4195 - val_accuracy: 0.8900\n",
            "Epoch 439/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1288 - accuracy: 0.9539 - val_loss: 0.4187 - val_accuracy: 0.8896\n",
            "Epoch 440/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1288 - accuracy: 0.9549 - val_loss: 0.4095 - val_accuracy: 0.8900\n",
            "Epoch 441/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1277 - accuracy: 0.9548 - val_loss: 0.4139 - val_accuracy: 0.8903\n",
            "Epoch 442/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1251 - accuracy: 0.9561 - val_loss: 0.4134 - val_accuracy: 0.8879\n",
            "Epoch 443/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1268 - accuracy: 0.9542 - val_loss: 0.4154 - val_accuracy: 0.8897\n",
            "Epoch 444/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1281 - accuracy: 0.9542 - val_loss: 0.4168 - val_accuracy: 0.8890\n",
            "Epoch 445/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1286 - accuracy: 0.9543 - val_loss: 0.4157 - val_accuracy: 0.8882\n",
            "Epoch 446/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1278 - accuracy: 0.9549 - val_loss: 0.4155 - val_accuracy: 0.8891\n",
            "Epoch 447/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1242 - accuracy: 0.9559 - val_loss: 0.4092 - val_accuracy: 0.8895\n",
            "Epoch 448/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1246 - accuracy: 0.9564 - val_loss: 0.4280 - val_accuracy: 0.8888\n",
            "Epoch 449/500\n",
            "48000/48000 [==============================] - 6s 120us/sample - loss: 0.1249 - accuracy: 0.9562 - val_loss: 0.4309 - val_accuracy: 0.8907\n",
            "Epoch 450/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1281 - accuracy: 0.9553 - val_loss: 0.4099 - val_accuracy: 0.8921\n",
            "Epoch 451/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1246 - accuracy: 0.9565 - val_loss: 0.4250 - val_accuracy: 0.8888\n",
            "Epoch 452/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1243 - accuracy: 0.9561 - val_loss: 0.4221 - val_accuracy: 0.8893\n",
            "Epoch 453/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1272 - accuracy: 0.9547 - val_loss: 0.4161 - val_accuracy: 0.8899\n",
            "Epoch 454/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1262 - accuracy: 0.9563 - val_loss: 0.4255 - val_accuracy: 0.8878\n",
            "Epoch 455/500\n",
            "48000/48000 [==============================] - 5s 112us/sample - loss: 0.1263 - accuracy: 0.9552 - val_loss: 0.4176 - val_accuracy: 0.8871\n",
            "Epoch 456/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1253 - accuracy: 0.9552 - val_loss: 0.4288 - val_accuracy: 0.8873\n",
            "Epoch 457/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1205 - accuracy: 0.9579 - val_loss: 0.4225 - val_accuracy: 0.8890\n",
            "Epoch 458/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1250 - accuracy: 0.9547 - val_loss: 0.4104 - val_accuracy: 0.8912\n",
            "Epoch 459/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1261 - accuracy: 0.9559 - val_loss: 0.4185 - val_accuracy: 0.8906\n",
            "Epoch 460/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1237 - accuracy: 0.9560 - val_loss: 0.4278 - val_accuracy: 0.8878\n",
            "Epoch 461/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1247 - accuracy: 0.9567 - val_loss: 0.4375 - val_accuracy: 0.8857\n",
            "Epoch 462/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1227 - accuracy: 0.9572 - val_loss: 0.4238 - val_accuracy: 0.8901\n",
            "Epoch 463/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1256 - accuracy: 0.9564 - val_loss: 0.4252 - val_accuracy: 0.8881\n",
            "Epoch 464/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1239 - accuracy: 0.9565 - val_loss: 0.4196 - val_accuracy: 0.8917\n",
            "Epoch 465/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1235 - accuracy: 0.9572 - val_loss: 0.4260 - val_accuracy: 0.8875\n",
            "Epoch 466/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1298 - accuracy: 0.9538 - val_loss: 0.4211 - val_accuracy: 0.8882\n",
            "Epoch 467/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1265 - accuracy: 0.9557 - val_loss: 0.4180 - val_accuracy: 0.8891\n",
            "Epoch 468/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1244 - accuracy: 0.9562 - val_loss: 0.4263 - val_accuracy: 0.8878\n",
            "Epoch 469/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1262 - accuracy: 0.9555 - val_loss: 0.4249 - val_accuracy: 0.8882\n",
            "Epoch 470/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1245 - accuracy: 0.9556 - val_loss: 0.4250 - val_accuracy: 0.8903\n",
            "Epoch 471/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1236 - accuracy: 0.9570 - val_loss: 0.4201 - val_accuracy: 0.8878\n",
            "Epoch 472/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1272 - accuracy: 0.9556 - val_loss: 0.4231 - val_accuracy: 0.8888\n",
            "Epoch 473/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1222 - accuracy: 0.9576 - val_loss: 0.4333 - val_accuracy: 0.8884\n",
            "Epoch 474/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1247 - accuracy: 0.9557 - val_loss: 0.4211 - val_accuracy: 0.8880\n",
            "Epoch 475/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1263 - accuracy: 0.9552 - val_loss: 0.4217 - val_accuracy: 0.8860\n",
            "Epoch 476/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1277 - accuracy: 0.9554 - val_loss: 0.4250 - val_accuracy: 0.8855\n",
            "Epoch 477/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1227 - accuracy: 0.9564 - val_loss: 0.4240 - val_accuracy: 0.8888\n",
            "Epoch 478/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1215 - accuracy: 0.9561 - val_loss: 0.4218 - val_accuracy: 0.8879\n",
            "Epoch 479/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1234 - accuracy: 0.9566 - val_loss: 0.4293 - val_accuracy: 0.8899\n",
            "Epoch 480/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1225 - accuracy: 0.9560 - val_loss: 0.4230 - val_accuracy: 0.8882\n",
            "Epoch 481/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1260 - accuracy: 0.9554 - val_loss: 0.4326 - val_accuracy: 0.8855\n",
            "Epoch 482/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1243 - accuracy: 0.9563 - val_loss: 0.4314 - val_accuracy: 0.8907\n",
            "Epoch 483/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1240 - accuracy: 0.9562 - val_loss: 0.4254 - val_accuracy: 0.8886\n",
            "Epoch 484/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1255 - accuracy: 0.9549 - val_loss: 0.4241 - val_accuracy: 0.8880\n",
            "Epoch 485/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1261 - accuracy: 0.9551 - val_loss: 0.4266 - val_accuracy: 0.8900\n",
            "Epoch 486/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1234 - accuracy: 0.9564 - val_loss: 0.4250 - val_accuracy: 0.8885\n",
            "Epoch 487/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1242 - accuracy: 0.9562 - val_loss: 0.4269 - val_accuracy: 0.8878\n",
            "Epoch 488/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1233 - accuracy: 0.9568 - val_loss: 0.4245 - val_accuracy: 0.8864\n",
            "Epoch 489/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1208 - accuracy: 0.9577 - val_loss: 0.4168 - val_accuracy: 0.8884\n",
            "Epoch 490/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1281 - accuracy: 0.9561 - val_loss: 0.4237 - val_accuracy: 0.8892\n",
            "Epoch 491/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1283 - accuracy: 0.9557 - val_loss: 0.4332 - val_accuracy: 0.8894\n",
            "Epoch 492/500\n",
            "48000/48000 [==============================] - 5s 110us/sample - loss: 0.1274 - accuracy: 0.9555 - val_loss: 0.4263 - val_accuracy: 0.8893\n",
            "Epoch 493/500\n",
            "48000/48000 [==============================] - 5s 108us/sample - loss: 0.1247 - accuracy: 0.9556 - val_loss: 0.4291 - val_accuracy: 0.8880\n",
            "Epoch 494/500\n",
            "48000/48000 [==============================] - 6s 119us/sample - loss: 0.1235 - accuracy: 0.9568 - val_loss: 0.4309 - val_accuracy: 0.8867\n",
            "Epoch 495/500\n",
            "48000/48000 [==============================] - 6s 117us/sample - loss: 0.1270 - accuracy: 0.9548 - val_loss: 0.4146 - val_accuracy: 0.8896\n",
            "Epoch 496/500\n",
            "48000/48000 [==============================] - 5s 107us/sample - loss: 0.1217 - accuracy: 0.9561 - val_loss: 0.4229 - val_accuracy: 0.8892\n",
            "Epoch 497/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1205 - accuracy: 0.9580 - val_loss: 0.4314 - val_accuracy: 0.8868\n",
            "Epoch 498/500\n",
            "48000/48000 [==============================] - 5s 109us/sample - loss: 0.1223 - accuracy: 0.9575 - val_loss: 0.4365 - val_accuracy: 0.8887\n",
            "Epoch 499/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1254 - accuracy: 0.9557 - val_loss: 0.4336 - val_accuracy: 0.8890\n",
            "Epoch 500/500\n",
            "48000/48000 [==============================] - 5s 111us/sample - loss: 0.1254 - accuracy: 0.9557 - val_loss: 0.4282 - val_accuracy: 0.8882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMhTCIoUAc62",
        "colab_type": "code",
        "outputId": "0ddda6e6-dc59-4a00-d052-37f97947497b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "loss, acc = model.evaluate(test_x, test_y, verbose=2)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Acc:\", acc)\n",
        "\n",
        "hist = history.history\n",
        "plt.plot(hist['loss'])\n",
        "plt.plot(hist['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 - 0s - loss: 0.4626 - accuracy: 0.8814\n",
            "Loss: 0.46261805201768874\n",
            "Acc: 0.8814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f7f37350-9936-455d-9f42-3dbd33c22e0e",
        "id": "FHoSxlQM_Rg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "result = np.argmax(pred[4])\n",
        "print(\"Prediction:\", result)\n",
        "print(\"True Label =\", classes[result])\n",
        "plt.imshow(test_x[4])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: 6\n",
            "True Label = Shirt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f431a9174a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkp2kUgo2UUioWQXiYSSXSQS/w9VK0sRmGlQQAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnck6dfYQafe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}